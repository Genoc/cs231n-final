{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull all data and fit on it - classify artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "- sanity check all my codes\n",
    "- add in actual test data instead of using just train/val\n",
    "- artists but use entire dataset, not a balanced version\n",
    "- copy of this, but for style instead\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.LongTensor'>\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "ytype = torch.LongTensor\n",
    "if (torch.cuda.is_available()):\n",
    "   dtype = torch.cuda.FloatTensor\n",
    "   ytype = torch.cuda.LongTensor\n",
    "print(ytype)\n",
    "print(dtype)\n",
    "print_every = 20\n",
    "\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "\n",
    "def train(model, loss_fn, optimizer, loader_train, loader_val, num_epochs = 1):\n",
    "    # train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    # val_loss_hist = []\n",
    "    val_acc_hist = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(dtype))\n",
    "            y_var = Variable(y.type(dtype).long())\n",
    "            scores = model(x_var)\n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # record training and validation accuracy at the end of each epoch\n",
    "        train_acc_hist.append(check_accuracy(model, loader_train))\n",
    "        val_acc_hist.append(check_accuracy(model, loader_val))\n",
    "        \n",
    "    return [train_acc_hist, val_acc_hist]\n",
    "    \n",
    "def check_accuracy(model, loader):\n",
    "    print('Checking accuracy!')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        y = y.view(-1, 1).type(ytype)\n",
    "        x_var = Variable(x.type(dtype), volatile=True)\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        \n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return 100*acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ALL MAIN ARGUMENTS FOR THE SCRIPT ##\n",
    "\n",
    "dat_folder = '../data/'\n",
    "img_folder = '../data/train_1/'\n",
    "\n",
    "filter_subset = True # True if we want to filter to just train _1\n",
    "\n",
    "## THIS VERSION OF SCRIPT HAS EQUAL NUMBER OF PAINTINGS PER ARTIST\n",
    "num_train = 40\n",
    "num_val = 10\n",
    "num_samples = num_train + num_val # threshold to include an artist\n",
    "b_size = 4 # batch size for the data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jan van Eyck</td>\n",
       "      <td>1439</td>\n",
       "      <td>religious painting</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>8311.0</td>\n",
       "      <td>28783029.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Northern Renaissance</td>\n",
       "      <td>The Madonna in the Church</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>16876.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Thomas Gainsborough</td>\n",
       "      <td>1783</td>\n",
       "      <td>landscape</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>11791905.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Rococo</td>\n",
       "      <td>The Mall in St. James's Park</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>1164.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Lyonel Feininger</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>cityscape</td>\n",
       "      <td>4472.0</td>\n",
       "      <td>5894.0</td>\n",
       "      <td>7382419.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>Gelmeroda IX</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>19385.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Henri de Toulouse-Lautrec</td>\n",
       "      <td>1895</td>\n",
       "      <td>genre painting</td>\n",
       "      <td>5833.0</td>\n",
       "      <td>3985.0</td>\n",
       "      <td>3389831.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Post-Impressionism</td>\n",
       "      <td>Abandonment (The pair)</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>17354.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       artist    date               genre  pixelsx  pixelsy  \\\n",
       "0              Barnett Newman  1955.0            abstract  15530.0   6911.0   \n",
       "23               Jan van Eyck    1439  religious painting   4000.0   8311.0   \n",
       "42        Thomas Gainsborough    1783           landscape   5712.0   4704.0   \n",
       "46           Lyonel Feininger  1926.0           cityscape   4472.0   5894.0   \n",
       "74  Henri de Toulouse-Lautrec    1895      genre painting   5833.0   3985.0   \n",
       "\n",
       "    size_bytes   source                 style                         title  \\\n",
       "0    9201912.0  wikiart  Color Field Painting                         Uriel   \n",
       "23  28783029.0  wikiart  Northern Renaissance     The Madonna in the Church   \n",
       "42  11791905.0  wikiart                Rococo  The Mall in St. James's Park   \n",
       "46   7382419.0  wikiart                Cubism                 Gelmeroda IX    \n",
       "74   3389831.0  wikiart    Post-Impressionism        Abandonment (The pair)   \n",
       "\n",
       "      artist_group  in_train new_filename  \n",
       "0       train_only      True   102257.jpg  \n",
       "23  train_and_test      True    16876.jpg  \n",
       "42  train_and_test      True     1164.jpg  \n",
       "46      train_only      True    19385.jpg  \n",
       "74  train_and_test      True    17354.jpg  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageFilter\n",
    "import random\n",
    "import cv2\n",
    "import os, glob\n",
    "\n",
    "t = pd.read_csv(dat_folder + 'all_data_info.csv')\n",
    "\n",
    "# filter down (if needed)\n",
    "if (filter_subset):\n",
    "    t = t[t['new_filename'].str.startswith('1')]\n",
    "    t = t[t['in_train']]\n",
    "\n",
    "t.head()\n",
    "# print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 artists being classified\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# list of all artists to include\n",
    "temp = t['artist'].value_counts()\n",
    "artists = temp[temp >= num_samples].index.tolist()\n",
    "num_artists = len(artists)\n",
    "\n",
    "print(str(len(artists)) + ' artists being classified')\n",
    "\n",
    "# pull train and val data for just those artists\n",
    "train_dfs = []\n",
    "val_dfs = []\n",
    "\n",
    "for a in artists:\n",
    "    df = t[t['artist'].str.startswith(a, na=False)].sample(n=num_samples)\n",
    "    t_df = df.sample(n=num_train)\n",
    "    v_df = df.loc[~df.index.isin(t_df.index)]\n",
    "    \n",
    "    train_dfs.append(t_df)\n",
    "    val_dfs.append(v_df)\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "val_df = pd.concat(val_dfs)\n",
    "\n",
    "# modify data to have numbers for artists and style, and create appropriate mappings\n",
    "unique_artists = train_df['artist'].str.upper().unique()\n",
    "unique_styles = train_df['style'].str.upper().unique()\n",
    "\n",
    "artist_l = {val: idx for (idx, val) in enumerate(unique_artists)}\n",
    "# style_l = {val: idx for (idx, val) in enumerate(unique_styles)}\n",
    "\n",
    "artist_labels = {idx: val for (idx, val) in enumerate(unique_artists)}\n",
    "# style_labels = {idx: val for (idx, val) in enumerate(unique_styles)}\n",
    "\n",
    "train_df['artist_label'] = np.array([artist_l[a] for a in train_df['artist'].str.upper().values])\n",
    "# train_df['style_label'] = np.array([style_l[a] for a in train_df['style'].str.upper().values])\n",
    "\n",
    "val_df['artist_label'] = np.array([artist_l[a] for a in val_df['artist'].str.upper().values])\n",
    "# val_df['style_label'] = np.array([style_l[a] for a in val_df['style'].str.upper().values])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display a few images by the artists\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageFilter\n",
    "import random\n",
    "import cv2\n",
    "import os, glob\n",
    "\n",
    "if len(artists) <= 4: # so we don't print this if it's too large\n",
    "    i_ = 1\n",
    "    plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    for a in artists:\n",
    "        print(a)\n",
    "        artist_df = t[t['artist'].str.startswith(a)]\n",
    "        imgs = []\n",
    "        for file in artist_df['new_filename']:\n",
    "            imgs.append(cv2.resize(cv2.imread(img_folder + file), (50,50)))\n",
    "        for img in imgs[10:20]:\n",
    "            plt.subplot(len(artists), 10, i_)\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
    "            i_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_tensors = []\n",
    "val_tensors = []\n",
    "\n",
    "# load in imags with cv2, then convert to matrices that work with pytorch\n",
    "train_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.RandomSizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Scale(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "for i in train_df['new_filename']:\n",
    "    # print('../data/train_1/' + i)\n",
    "    img = cv2.imread(img_folder + i)\n",
    "    \n",
    "    # transforms and make a Tensor\n",
    "    img_tensor = train_transform(img)\n",
    "    train_tensors.append(img_tensor)\n",
    "\n",
    "for i in val_df['new_filename']:\n",
    "    img = cv2.imread(img_folder + i)\n",
    "    \n",
    "    # transforms and make a Tensor\n",
    "    img_tensor = val_transform(img)\n",
    "    val_tensors.append(img_tensor)\n",
    "    \n",
    "train_tensors = torch.stack(train_tensors)\n",
    "val_tensors = torch.stack(val_tensors)\n",
    "\n",
    "# create DataLoaders\n",
    "train_labels = torch.Tensor(train_df['artist_label'].values.astype(np.float32))\n",
    "val_labels = torch.Tensor(val_df['artist_label'].values.astype(np.float32))\n",
    "\n",
    "train_dset = TensorDataset(train_tensors, train_labels)\n",
    "loader_train = DataLoader(train_dset, batch_size=b_size, shuffle=True)\n",
    "    \n",
    "val_dset = TensorDataset(val_tensors, val_labels)\n",
    "loader_val = DataLoader(val_dset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a simple network to use as a baseline\n",
    "\n",
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1), # -> 112\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(2), # -> 56\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1), # -> 28\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.MaxPool2d(2), # -> 14\n",
    "    Flatten(),\n",
    "    nn.Linear(6272, 200),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(200, num_artists),\n",
    ")\n",
    "\n",
    "simple_model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=1e-2)\n",
    "optimizer2 = optim.Adam(simple_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we're going to feed a random batch into the model and make sure the output is the right size\n",
    "x = torch.randn(64, 3, 224, 224).type(dtype)\n",
    "x_var = Variable(x.type(dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = simple_model(x_var)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, num_artists]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 20, loss = 1.7483\n",
      "t = 40, loss = 2.2504\n",
      "t = 60, loss = 2.0650\n",
      "t = 80, loss = 1.0502\n",
      "t = 100, loss = 2.4221\n",
      "t = 120, loss = 2.2931\n",
      "t = 140, loss = 2.6001\n",
      "t = 160, loss = 1.7515\n",
      "t = 180, loss = 1.0984\n",
      "t = 200, loss = 1.3086\n",
      "t = 220, loss = 2.0498\n",
      "t = 240, loss = 1.5552\n",
      "Checking accuracy!\n",
      "Got 611 / 960 correct (63.65)\n",
      "Checking accuracy!\n",
      "Got 60 / 240 correct (25.00)\n",
      "Starting epoch 2 / 5\n",
      "t = 20, loss = 0.9241\n",
      "t = 40, loss = 0.5869\n",
      "t = 60, loss = 1.0100\n",
      "t = 80, loss = 0.5668\n",
      "t = 100, loss = 0.8845\n",
      "t = 120, loss = 0.5611\n",
      "t = 140, loss = 0.3163\n",
      "t = 160, loss = 0.8038\n",
      "t = 180, loss = 0.3788\n",
      "t = 200, loss = 0.2924\n",
      "t = 220, loss = 0.6164\n",
      "t = 240, loss = 0.6700\n",
      "Checking accuracy!\n",
      "Got 888 / 960 correct (92.50)\n",
      "Checking accuracy!\n",
      "Got 58 / 240 correct (24.17)\n",
      "Starting epoch 3 / 5\n",
      "t = 20, loss = 0.1022\n",
      "t = 40, loss = 0.1384\n",
      "t = 60, loss = 0.0971\n",
      "t = 80, loss = 0.5383\n",
      "t = 100, loss = 0.2298\n",
      "t = 120, loss = 0.0283\n",
      "t = 140, loss = 0.0188\n",
      "t = 160, loss = 0.0282\n",
      "t = 180, loss = 0.5108\n",
      "t = 200, loss = 0.2847\n",
      "t = 220, loss = 0.0171\n",
      "t = 240, loss = 0.0452\n",
      "Checking accuracy!\n",
      "Got 931 / 960 correct (96.98)\n",
      "Checking accuracy!\n",
      "Got 55 / 240 correct (22.92)\n",
      "Starting epoch 4 / 5\n",
      "t = 20, loss = 0.0145\n",
      "t = 40, loss = 0.1326\n",
      "t = 60, loss = 0.1768\n",
      "t = 80, loss = 0.1197\n",
      "t = 100, loss = 0.0187\n",
      "t = 120, loss = 0.2152\n",
      "t = 140, loss = 0.0033\n",
      "t = 160, loss = 0.0372\n",
      "t = 180, loss = 0.0655\n",
      "t = 200, loss = 1.3133\n",
      "t = 220, loss = 0.0175\n",
      "t = 240, loss = 0.0369\n",
      "Checking accuracy!\n",
      "Got 938 / 960 correct (97.71)\n",
      "Checking accuracy!\n",
      "Got 54 / 240 correct (22.50)\n",
      "Starting epoch 5 / 5\n",
      "t = 20, loss = 0.0936\n",
      "t = 40, loss = 0.0059\n",
      "t = 60, loss = 0.0085\n",
      "t = 80, loss = 0.0399\n",
      "t = 100, loss = 0.0025\n",
      "t = 120, loss = 0.0294\n",
      "t = 140, loss = 0.0080\n",
      "t = 160, loss = 0.0170\n",
      "t = 180, loss = 0.0412\n",
      "t = 200, loss = 0.0153\n",
      "t = 220, loss = 0.0063\n",
      "t = 240, loss = 0.0324\n",
      "Checking accuracy!\n",
      "Got 950 / 960 correct (98.96)\n",
      "Checking accuracy!\n",
      "Got 55 / 240 correct (22.92)\n"
     ]
    }
   ],
   "source": [
    "# apply my simple network to the dataset\n",
    "# reset(simple_model)\n",
    "# train(simple_model, loss_fn, optimizer, loader_train, num_epochs = 5)\n",
    "train_acc_hist, val_acc_hist = train(simple_model, loss_fn, optimizer2, loader_train, loader_val, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.645833333333336, 92.5, 96.97916666666667, 97.70833333333333, 98.95833333333334]\n",
      "[25.0, 24.166666666666668, 22.916666666666664, 22.5, 22.916666666666664]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc_hist)\n",
    "print(val_acc_hist)\n",
    "\n",
    "# training accuracy over time chart - showing the overfit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer learning on top of ResNet18\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
